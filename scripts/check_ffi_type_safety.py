#!/usr/bin/env python3
"""
FFI å‹å®‰å…¨æ€§ãƒã‚§ãƒƒã‚¯ã‚¹ã‚¯ãƒªãƒ—ãƒˆ

tl_runtime ã® @ffi_sig ã‚³ãƒ¡ãƒ³ãƒˆã§å®£è¨€ã•ã‚ŒãŸæ„å‘³çš„å‹æƒ…å ±ã¨ã€
ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰ï¼ˆcodegenï¼‰ã§ã®å‘¼ã³å‡ºã—ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’ç…§åˆã—ã€
å‹ã®ä¸æ•´åˆã‚’æ—©æœŸã«æ¤œå‡ºã™ã‚‹ã€‚

ä½¿ã„æ–¹:
    python scripts/check_ffi_type_safety.py [--verbose]
"""

import re
import sys
from pathlib import Path
from dataclasses import dataclass, field
from typing import Optional

# ============================================================
# å®šæ•°
# ============================================================
SCRIPT_DIR = Path(__file__).resolve().parent
PROJECT_ROOT = SCRIPT_DIR.parent

# @ffi_sig ã‚’ã‚¹ã‚­ãƒ£ãƒ³ã™ã‚‹ãƒ©ãƒ³ã‚¿ã‚¤ãƒ ã‚½ãƒ¼ã‚¹
RUNTIME_SOURCES = [
    PROJECT_ROOT / "crates" / "tl_runtime" / "src",
]

# ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰ codegen ã‚½ãƒ¼ã‚¹
FRONTEND_SOURCES = [
    PROJECT_ROOT / "src" / "compiler" / "codegen",
]

# å‹ã®äº’æ›æ€§ãƒãƒˆãƒªã‚¯ã‚¹
# key: @ffi_sig å‹, value: äº’æ› TL å‹ã®ã‚»ãƒƒãƒˆ
TYPE_COMPAT = {
    "Tensor*": {"Tensor", "TensorShaped"},
    "Struct*": {"Struct"},
    "String*": {"String"},
    "void*":   {"Tensor", "TensorShaped", "Struct", "String", "void", "any"},  # æ±ç”¨
    "i8*":     {"cstr"},
    "i64":     {"i64", "int"},
    "f32":     {"f32", "float"},
    "f64":     {"f64", "float"},
    "bool":    {"bool"},
    "usize":   {"usize", "u64"},
    "u32":     {"u32"},
}


# ============================================================
# ãƒ‡ãƒ¼ã‚¿å‹
# ============================================================
@dataclass
class FfiSig:
    """@ffi_sig ã§å®£è¨€ã•ã‚ŒãŸå‹æƒ…å ±"""
    fn_name: str
    params: list[str]       # æ„å‘³çš„å‹åãƒªã‚¹ãƒˆ (e.g. ["Tensor*", "i64"])
    return_type: str        # "void" | "Tensor*" | "i64" etc.
    source_file: str = ""
    line: int = 0

    def sig_str(self) -> str:
        params = ", ".join(self.params) if self.params else ""
        return f"({params}) -> {self.return_type}"


@dataclass
class CallSite:
    """ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰ã§ã® FFI å‘¼ã³å‡ºã—ç®‡æ‰€"""
    fn_name: str            # å‘¼ã³å‡ºã™ FFI é–¢æ•°å
    context_type: str       # å‘¼ã³å‡ºã—ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰æ¨å®šã—ãŸå‹ (e.g. "Tensor", "Struct")
    source_file: str = ""
    line: int = 0
    arg_count: Optional[int] = None  # build_call ã®å¼•æ•°æ•° (æŠ½å‡ºã§ããŸå ´åˆ)
    context_snippet: str = ""  # å‘¨è¾ºã‚³ãƒ¼ãƒ‰


# ============================================================
# ãƒ©ãƒ³ã‚¿ã‚¤ãƒ  @ffi_sig ãƒ‘ãƒ¼ã‚µãƒ¼
# ============================================================
RE_FFI_SIG = re.compile(
    r'///\s*@ffi_sig\s+\(([^)]*)\)\s*->\s*(\S+)'
)
RE_FN_NAME = re.compile(
    r'pub\s+extern\s+"C"\s+fn\s+(\w+)'
)


def parse_ffi_sigs(filepath: Path) -> dict[str, FfiSig]:
    """ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ @ffi_sig ã‚³ãƒ¡ãƒ³ãƒˆã‚’æŠ½å‡º"""
    if not filepath.exists():
        return {}

    content = filepath.read_text(encoding="utf-8")
    lines = content.split("\n")
    result = {}

    pending_sig: Optional[tuple[list[str], str, int]] = None

    for i, line in enumerate(lines):
        # @ffi_sig ã‚’æ¤œå‡º
        m = RE_FFI_SIG.search(line)
        if m:
            raw_params = m.group(1).strip()
            ret_type = m.group(2).strip()
            params = [p.strip() for p in raw_params.split(",") if p.strip()] if raw_params else []
            pending_sig = (params, ret_type, i + 1)
            continue

        # ç›´å¾Œã® extern "C" fn ã‚’æ¤œå‡º
        if pending_sig:
            fn_m = RE_FN_NAME.search(line)
            if fn_m:
                fn_name = fn_m.group(1)
                params, ret_type, sig_line = pending_sig
                result[fn_name] = FfiSig(
                    fn_name=fn_name,
                    params=params,
                    return_type=ret_type,
                    source_file=str(filepath.relative_to(PROJECT_ROOT)),
                    line=sig_line,
                )
                pending_sig = None
            elif line.strip() and not line.strip().startswith("///") and not line.strip().startswith("#["):
                # ã‚³ãƒ¡ãƒ³ãƒˆã‚„ã‚¢ãƒˆãƒªãƒ“ãƒ¥ãƒ¼ãƒˆä»¥å¤–ã®è¡ŒãŒæ¥ãŸã‚‰ pending ã‚’ç ´æ£„
                pending_sig = None

    return result


def collect_ffi_sigs() -> dict[str, FfiSig]:
    """å…¨ãƒ©ãƒ³ã‚¿ã‚¤ãƒ ã‚½ãƒ¼ã‚¹ã‹ã‚‰ @ffi_sig ã‚’åé›†"""
    all_sigs: dict[str, FfiSig] = {}
    for src_dir in RUNTIME_SOURCES:
        if not src_dir.exists():
            continue
        for rs_file in src_dir.rglob("*.rs"):
            if ".bak" in str(rs_file) or ".orig" in str(rs_file):
                continue
            sigs = parse_ffi_sigs(rs_file)
            all_sigs.update(sigs)
    return all_sigs


# ============================================================
# ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰å‘¼ã³å‡ºã—è§£æ
# ============================================================

# match ty ã®ãƒ‘ã‚¿ãƒ¼ãƒ³æ¤œå‡º
RE_TYPE_MATCH = re.compile(
    r'Type::(Tensor|TensorShaped|Struct|String|Enum|Tuple|Int|Float|Bool)'
)

# get_function("xxx") ã®æ¤œå‡º
RE_GET_FUNCTION = re.compile(
    r'get_function\(\s*"(\w+)"\s*\)'
)

# build_call ã®å¼•æ•°æ•°æ¤œå‡º (æ¦‚ç®—)
RE_BUILD_CALL_ARGS = re.compile(
    r'build_call\([^,]+,\s*&\[([^\]]*)\]'
)


def analyze_frontend_calls(filepath: Path) -> list[CallSite]:
    """ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰ã‚½ãƒ¼ã‚¹ã‹ã‚‰ FFI å‘¼ã³å‡ºã—ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’è§£æ"""
    if not filepath.exists():
        return []

    content = filepath.read_text(encoding="utf-8")
    lines = content.split("\n")
    calls: list[CallSite] = []

    # ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæ¨å®š: match ty => ... Type::Xxx => ... get_function("tl_yyy")
    # ã‚¹ã‚³ãƒ¼ãƒ—ã‚¹ã‚¿ãƒƒã‚¯ã§ç¾åœ¨ã®å‹ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’è¿½è·¡
    current_type_context: list[str] = []
    brace_depth = 0
    type_context_depths: list[int] = []

    for i, line in enumerate(lines):
        stripped = line.strip()

        # ãƒ–ãƒ¬ãƒ¼ã‚¹ã®æ·±ã•ã‚’è¿½è·¡
        brace_depth += line.count("{") - line.count("}")

        # Type::Xxx ãƒ‘ã‚¿ãƒ¼ãƒ³ã®æ¤œå‡º
        type_matches = RE_TYPE_MATCH.findall(line)
        for tm in type_matches:
            if "=>" in line or "match" in line.lower() or "if " in line:
                current_type_context.append(tm)
                type_context_depths.append(brace_depth)

        # å¤ã„ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã®å‰Šé™¤
        while type_context_depths and brace_depth < type_context_depths[-1]:
            type_context_depths.pop()
            if current_type_context:
                current_type_context.pop()

        # get_function ã®æ¤œå‡º
        fn_match = RE_GET_FUNCTION.search(line)
        if fn_match:
            fn_name = fn_match.group(1)
            ctx = current_type_context[-1] if current_type_context else "unknown"

            # å‰å¾Œ5è¡Œã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’ã‚¹ãƒ‹ãƒšãƒƒãƒˆã¨ã—ã¦ä¿å­˜
            start = max(0, i - 3)
            end = min(len(lines), i + 4)
            snippet = "\n".join(lines[start:end])

            calls.append(CallSite(
                fn_name=fn_name,
                context_type=ctx,
                source_file=str(filepath.relative_to(PROJECT_ROOT)),
                line=i + 1,
                context_snippet=snippet,
            ))

    return calls


def collect_frontend_calls() -> list[CallSite]:
    """å…¨ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰ã‚½ãƒ¼ã‚¹ã‹ã‚‰ FFI å‘¼ã³å‡ºã—ã‚’åé›†"""
    all_calls: list[CallSite] = []
    for src_dir in FRONTEND_SOURCES:
        if not src_dir.exists():
            continue
        for rs_file in src_dir.rglob("*.rs"):
            calls = analyze_frontend_calls(rs_file)
            all_calls.extend(calls)
    return all_calls


# ============================================================
# æ•´åˆæ€§ãƒã‚§ãƒƒã‚¯
# ============================================================

def check_type_compat(ffi_sig: FfiSig, call: CallSite) -> Optional[str]:
    """
    @ffi_sig ã®å‹ã¨ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰ã®å‘¼ã³å‡ºã—ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆå‹ã®äº’æ›æ€§ãƒã‚§ãƒƒã‚¯ã€‚
    
    æˆ»ã‚Šå€¤: ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ (å•é¡Œãªã‘ã‚Œã° None)
    """
    # å¼•æ•°ã®ãªã„é–¢æ•°ã¯ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆä¸å•
    if not ffi_sig.params:
        return None

    ctx = call.context_type
    if ctx == "unknown":
        return None  # ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆä¸æ˜ã¯ã‚¹ã‚­ãƒƒãƒ—

    # ç¬¬1å¼•æ•°ã®å‹ãƒã‚§ãƒƒã‚¯ (æœ€ã‚‚é‡è¦)
    first_param = ffi_sig.params[0]

    # ãƒ‘ã‚¤ãƒ—è¨˜æ³•å¯¾å¿œ: "Struct*|String*" â†’ ["Struct*", "String*"]
    param_alternatives = [p.strip() for p in first_param.split("|")]

    # å„ä»£æ›¿å‹ã®äº’æ›å‹ã‚’é›†ç´„
    compat_types: set[str] = set()
    for alt in param_alternatives:
        compat_types.update(TYPE_COMPAT.get(alt, set()))

    if not compat_types:
        return None  # æœªçŸ¥ã®å‹ã¯ã‚¹ã‚­ãƒƒãƒ—

    # void* ã¯ã™ã¹ã¦ã¨äº’æ›
    if "void*" in param_alternatives:
        return None

    # TLå‹ãŒæœŸå¾…ã•ã‚Œã‚‹å‹ã¨äº’æ›ã‹ãƒã‚§ãƒƒã‚¯
    if ctx not in compat_types:
        return (
            f"å‹ä¸æ•´åˆ: {call.fn_name}\n"
            f"   @ffi_sig ç¬¬1å¼•æ•°: {first_param} (æœŸå¾…: {compat_types})\n"
            f"   å‘¼ã³å‡ºã—ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ: Type::{ctx}\n"
            f"   å ´æ‰€: {call.source_file}:{call.line}"
        )

    return None


# ============================================================
# ãƒ¬ãƒãƒ¼ãƒˆ: @ffi_sig ã‚«ãƒãƒ¬ãƒƒã‚¸
# ============================================================

RE_EXTERN_FN = re.compile(
    r'(?:pub\s+)?(?:#\[[\w()\s]*\]\s*)*(?:pub\s+)?extern\s+"C"\s+fn\s+(\w+)',
)


def find_uncovered_fns() -> list[tuple[str, str, int]]:
    """@ffi_sig ã‚³ãƒ¡ãƒ³ãƒˆãŒãªã„ extern "C" fn ã‚’æ¤œå‡º"""
    uncovered = []
    for src_dir in RUNTIME_SOURCES:
        if not src_dir.exists():
            continue
        for rs_file in src_dir.rglob("*.rs"):
            if ".bak" in str(rs_file) or ".orig" in str(rs_file):
                continue
            content = rs_file.read_text(encoding="utf-8")
            lines = content.split("\n")
            for i, line in enumerate(lines):
                fn_m = RE_EXTERN_FN.search(line)
                if fn_m and 'extern "C" fn' in line:
                    fn_name = fn_m.group(1)
                    # ç›´å‰ã®è¡Œã« @ffi_sig ãŒã‚ã‚‹ã‹ç¢ºèª (æœ€å¤§10è¡Œé¡ã‚‹)
                    has_sig = False
                    for j in range(max(0, i - 10), i):
                        if "@ffi_sig" in lines[j]:
                            has_sig = True
                            break
                    if not has_sig:
                        rel_path = str(rs_file.relative_to(PROJECT_ROOT))
                        uncovered.append((fn_name, rel_path, i + 1))
    return uncovered


# ============================================================
# ãƒ¡ã‚¤ãƒ³
# ============================================================

def main():
    verbose = "--verbose" in sys.argv or "-v" in sys.argv

    print("ğŸ” FFI å‹å®‰å…¨æ€§ãƒã‚§ãƒƒã‚¯ãƒ„ãƒ¼ãƒ«")
    print(f"   ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ: {PROJECT_ROOT}")
    print()

    # --- 1. @ffi_sig åé›† ---
    ffi_sigs = collect_ffi_sigs()
    print(f"ğŸ“‹ @ffi_sig å®šç¾©:    {len(ffi_sigs)} å€‹")

    if verbose:
        for name, sig in sorted(ffi_sigs.items()):
            print(f"   {name}: {sig.sig_str()}  ({sig.source_file}:{sig.line})")
        print()

    # --- 2. ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰å‘¼ã³å‡ºã—åé›† ---
    calls = collect_frontend_calls()
    print(f"ğŸ“ FFI å‘¼ã³å‡ºã—ç®‡æ‰€: {len(calls)} å€‹")
    print()

    # --- 3. å‹æ•´åˆæ€§ãƒã‚§ãƒƒã‚¯ ---
    issues: list[str] = []
    checked = 0
    skipped = 0

    for call in calls:
        if call.fn_name in ffi_sigs:
            sig = ffi_sigs[call.fn_name]
            error = check_type_compat(sig, call)
            if error:
                issues.append(error)
            checked += 1
            if verbose and not error:
                print(f"   âœ… {call.fn_name} ({call.context_type}) @ {call.source_file}:{call.line}")
        else:
            skipped += 1

    # --- 4. ã‚«ãƒãƒ¬ãƒƒã‚¸ãƒã‚§ãƒƒã‚¯ ---
    uncovered = find_uncovered_fns()

    # --- 5. çµæœè¡¨ç¤º ---
    print("=" * 60)
    print("æ¤œæŸ»çµæœ")
    print("=" * 60)

    if issues:
        print(f"\nğŸš¨ å‹ä¸æ•´åˆ: {len(issues)} ä»¶\n")
        for issue in issues:
            print(f"âŒ {issue}")
            print()
    else:
        print("\nâœ… å‹ä¸æ•´åˆã¯æ¤œå‡ºã•ã‚Œã¾ã›ã‚“ã§ã—ãŸã€‚\n")

    # ã‚«ãƒãƒ¬ãƒƒã‚¸ãƒ¬ãƒãƒ¼ãƒˆ
    if uncovered:
        print(f"ğŸ“Š @ffi_sig æœªå®šç¾©ã®é–¢æ•°: {len(uncovered)} å€‹\n")
        # ãƒ•ã‚¡ã‚¤ãƒ«ã”ã¨ã«ã‚°ãƒ«ãƒ¼ãƒ—åŒ–
        by_file: dict[str, list[tuple[str, int]]] = {}
        for fn_name, path, line in uncovered:
            by_file.setdefault(path, []).append((fn_name, line))
        for path, fns in sorted(by_file.items()):
            print(f"   ğŸ“ {path}:")
            for fn_name, line in fns:
                print(f"      - {fn_name} (L{line})")
        print()

    # --- ã‚µãƒãƒªãƒ¼ ---
    print("-" * 60)
    print(f"ğŸ“Š ã‚µãƒãƒªãƒ¼:")
    print(f"   @ffi_sig å®šç¾©æ¸ˆã¿:          {len(ffi_sigs)}")
    print(f"   ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰ FFI å‘¼ã³å‡ºã—: {len(calls)}")
    print(f"   ãƒã‚§ãƒƒã‚¯æ¸ˆã¿:               {checked}")
    print(f"   @ffi_sig æœªå¯¾å¿œ (ã‚¹ã‚­ãƒƒãƒ—): {skipped}")
    print(f"   å‹ä¸æ•´åˆ:                   {len(issues)}")
    print(f"   @ffi_sig æœªå®šç¾©é–¢æ•°:        {len(uncovered)}")

    ffi_sig_coverage = len(ffi_sigs) / (len(ffi_sigs) + len(uncovered)) * 100 if (len(ffi_sigs) + len(uncovered)) > 0 else 0
    print(f"   ã‚«ãƒãƒ¬ãƒƒã‚¸:                 {ffi_sig_coverage:.1f}%")

    if issues:
        print(f"\nğŸ’¡ å‹ä¸æ•´åˆãŒæ¤œå‡ºã•ã‚Œã¾ã—ãŸã€‚ä¿®æ­£ãŒå¿…è¦ã§ã™ã€‚")
        return 1
    return 0


if __name__ == "__main__":
    sys.exit(main())
